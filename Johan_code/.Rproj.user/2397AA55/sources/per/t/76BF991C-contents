library(mvtnorm)
source("./estim.r")
source("./asvar-gauss.r")

# random sampling from distribution of X given Y=+1
# INPUT
# n : sample size
# OUTPUT
# a matrix of size n-by-2; the rows are iid draws from the bivariate standard normal distribution
# Below, other data-generating processes are considered.
P.pl <- function(n) {
  rmvnorm(n, mean = c(0,0), sigma = diag(1, nrow = 2))
}

# random sampling from distribution of X given Y=-1
# INPUT
# n : sample size
# OUTPUT
# a matrix of size n-by-2; the rows are iid draws from a certain standard normal distribution
# Below, other data-generating processes are considered.
P.mn <- function(n) {
  rmvnorm(n, mean = c(2,1), sigma = cbind(c(2, 1), c(1, 2)))
}

# random sampling of target sample
# INPUT
# n.tg  : size of the target sample
# P.pl  : function to simulate from X given Y = +1
# P.mn  : function to simulate from X given Y = -1
# pi.tg : real number between 0 and 1; probability of positive cases in target sample
# P.pl and P.mn should produce data matrices with the same number of columns (column vectors if only one column)
# OUTPUT
# a matrix of size n.tg times p, where p is the common dimension of the samples generated by P.pl and P.mn
P.tg <- function(n.tg, P.pl, P.mn, pi.tg) {
  Y <- sample(x = c(-1,1), size = n.tg, replace = TRUE, prob = c(1-pi.tg, pi.tg))
  I <- which(Y > 0)
  n.pl <- length(I)
  n.mn <- n.tg - n.pl
  if (n.pl < 1) { # no positive samples
    x.tg <- P.mn(n.tg)
  } else if (n.mn < 1) { # no negative sample
    x.tg <- P.pl(n.tg)
  } else { # both positive and negative samples
    x.pl <- P.pl(n.pl)
    x.mn <- P.mn(n.mn)
    x.tg <- matrix(0, nrow = n.tg, ncol = ncol(x.pl))
    x.tg[ I, ] <- x.pl
    x.tg[-I, ] <- x.mn
  }
  return(x.tg)
}

# kernel function
# INPUT
# x, y : vectors of the same size
# OUTPUT
# the value of exp(-\| x-y \|^2/(2\sigma^2)) with \sigma = 0.5
K <- function(x,y) {
  # function K.gauss defined in <estim.r>
  K.gauss(x, y, sig = 0.5)
}

# function to simulation experiment
# INPUT
# n.mn  : size of the 'minus' sample
# n.pl  : size of the 'plus' sample
# n.tg  : size of the target sample
# K     : the kernel function
# P.pl  : function to simulate from X given Y = +1
# P.mn  : function to simulate from X given Y = -1
# pi.tg : real number between 0 and 1; probability of positive cases in target sample
# rplc  : number of replications
# graph : if TRUE, then a boxplot of the estimates will be produced, with the true probability as a blue line
# P.pl and P.mn should produce data matrices with the same number of columns (column vectors if only one column)
# OUTPUT
# a matrix of size rplc-by-2
# first column: the ratio (norm) estimator
# second column: the projection (inner-product) based estimator
rpi.estim <- function(P.pl, P.mn, pi.tg, n.pl, n.mn, n.tg, K, rplc, graph = TRUE) {
  estim <- cbind(pi.nrm = numeric(rplc), pi.ipr = numeric(rplc))
  
  for (i in 1:rplc) {
    x.pl <- P.pl(n.pl)
    x.mn <- P.mn(n.mn)
    x.tg <- P.tg(n.tg, P.pl, P.mn, pi.tg)

    # function pi.estim() defined in <estim.r>
    estim[i, ] <- pi.estim(x.tg, x.pl, x.mn, K)
  }
  if (graph) {
    boxplot(estim, cex.lab = 2, cex.axis = 2)
    abline(h = pi.tg, col = "blue")
    title(main = paste0("n' = ", n.tg, ", n_+ = ", n.pl, ", n_- = ", n.mn, "; ", rplc, " replications"),
          cex.main = 2)
  }
  return(estim)
}

# boxplots comparing the two estimators
if (FALSE) { # set this to TRUE to run the experiment
  res.pi <- rpi.estim(P.pl, P.mn, pi.tg = 0.25, n.pl = 200, n.mn = 150, n.tg = 100, K = K, rplc = 100)  
}


# check whether two different implementations of the projection (inner-product based) estimator agree 
# - check OK
if (FALSE) { # set this to TRUE to run the experiment
  x.pl <- P.pl(20)
  x.mn <- P.mn(30)
  x.tg <- P.tg(40, P.pl, P.mn, 0.4)
  
  # functions pi.estim() and pi.estim.var() defined in <estim.r>
  c(pi.estim(x.tg, x.pl, x.mn, K)["pi.ipr"], pi.estim.var(x.tg, x.pl, x.mn, K)["pi.ipr"])
}

# simulation experiment evaluating the projection (inner-product) based estimator
if (FALSE) { # set this to TRUE to run the experiment
  # simulation settings
  rplc <- 100 # number of replications
  n.pl <- 150 # size of the 'plus' sample
  n.mn <- 200 # size of the 'minus' sample
  n.tg <- 250 # size of the target sample
  pi.tg <- 0.4 # probability of positive cases in target sample
  
  # object in which simulation results will be stored
  # first column:  the estimates
  # second column: the estimated standard errors
  # third column:  the studentized estimation errors (should look asymptotically standard normal)
  res <- data.frame(pi.ipr = numeric(rplc), std.err = numeric(rplc), an = numeric(rplc))
  
  for (i in 1:rplc) {
    x.pl <- P.pl(n.pl) # draw the 'plus' sample
    x.mn <- P.mn(n.mn) # draw the 'minus' sample
    x.tg <- P.tg(n.tg, P.pl, P.mn, pi.tg) # draw the target sample
    # function pi.estim.var() defined in <estim.r>
    tmp <- pi.estim.var(x.tg, x.pl, x.mn, K) # compute the estimate and the estimated standard error
    res$pi.ipr[i] <- tmp["pi.ipr"]
    res$std.err[i] <- tmp["std.err"]
  }
  res$an <- (res$pi.ipr - pi.tg) / res$std.err # studentized standard errors
  # save(res, n.pl, n.mn, n.tg, pi.tg, P.pl, P.mn, K, file = "simu.RData")
  
  # summary statistics
  summary(res)
  
  # four diagnostic plots
  par(mfrow = c(2,2))
  # 1. boxplot of estimates and true value
  boxplot(res$pi.ipr)
  title(main = "estimates", 
        sub = paste0("n' = ", n.tg, ", n_+ = ", n.pl, ", n_- = ", n.mn, "; ", rplc, " replications"))
  abline(h = pi.tg, col = "blue")
  # 2. boxplot of estimated standard errors
  boxplot(res$std.err)
  title(main = "estimated standard errors")
  # 3. quantile-quantile plot of studentized estimation errors
  qqnorm(res$an, main = "Normal QQ plot of standardized estimation errors")
  abline(a = 0, b = 1)
  # 4. histogram of studentized estimation errors together with standard normal density function
  hist(res$an, freq = FALSE, main = "Histogram of standardized estimation errors", 
       xlab = "standardized estimation errors")
  curve(dnorm(x), add = TRUE)
}

# simulation experiment evaluating the projection (inner-product) based estimator
# and compare the estimated standard errors with the theoretical ones
if (TRUE) {
  # random sampling from distributions of X given Y=+1 and Y=-1
  # both distributions are trivariate normal with certain mean vectors and covariance matrices
  mu.pl <- c(0,0,0)
  Sig.pl <- diag(1, nrow = 3)
  mu.mn <- c(2, 1, -1)
  Sig.mn <- rbind(c(1, 0.5, 0), 
                  c(0.5, 1, 0.5),
                  c(0, 0.5, 1))
  P.pl <- function(n) {
    rmvnorm(n, mean = mu.pl, sigma = Sig.pl)
  }
  P.mn <- function(n) {
    rmvnorm(n, mean = mu.mn, sigma = Sig.mn)
  }

  rplc <- 200  # number of replications
  sig <- 0.8   # parameter of the kernel functions
  n.pl <- 500  # size of the 'plus' sample
  n.mn <- 400  # size of the 'minus' sample
  n.tg <- 300  # size of the target sample
  pi.tg <- 0.4 # target probability
  denominator <- 1/n.tg + 1/n.pl + 1/n.mn # normalization factor in central limit theorem
  lam.tg <- (1/n.tg) / denominator
  lam.pl <- (1/n.pl) / denominator
  lam.mn <- (1/n.mn) / denominator
  # asymptotic standard error of the projection (inner-product) estimator in the Gaussian case
  # function asvar.pi.ipr() defined in <asvar-gauss.r>
  sd.th <- sqrt(asvar.pi.ipr(lam.tg, lam.pl, lam.mn, pi.tg, mu.pl, Sig.pl, mu.mn, Sig.mn, sig) *
                  denominator)
  
  # object in which simulation results will be stored
  # first column:  the estimates
  # second column: the estimated standard errors
  # third column:  the studentized estimation errors (should look asymptotically standard normal)
  res <- data.frame(pi.ipr = numeric(rplc), std.err = numeric(rplc), an = numeric(rplc))
  for (i in 1:rplc) {
    x.pl <- P.pl(n.pl)
    x.mn <- P.mn(n.mn)
    x.tg <- P.tg(n.tg, P.pl, P.mn, pi.tg)
    # function pi.estim.var() defined in <estim.r>
    tmp <- pi.estim.var(x.tg, x.pl, x.mn, K)
    res$pi.ipr[i] <- tmp["pi.ipr"]
    res$std.err[i] <- tmp["std.err"]
  }
  res$an <- (res$pi.ipr - pi.tg) / res$std.err
  # save(res, n.pl, n.mn, n.tg, pi.tg, P.pl, P.mn, K, file = "simu.RData")

  # some summary statistics  
  summary(res)
  
  # four diagnostic plots
  par(mfrow = c(2,2))

  # 1. boxplot of estimates and true value
  boxplot(res$pi.ipr)
  title(main = "estimates", 
        sub = paste0("n' = ", n.tg, ", n_+ = ", n.pl, ", n_- = ", n.mn, "; ", rplc, " replications"))
  abline(h = pi.tg, col = "blue")
  
  # 2. boxplot of estimated standard errors and asymptotic standard error according to theory
  boxplot(res$std.err)
  title(main = "estimated standard errors")
  abline(h = sd.th, col = "blue")
  
  # 3. quantile-quantile plot of studentized estimation errors
  qqnorm(res$an, main = "Normal QQ plot of standardized estimation errors")
  abline(a = 0, b = 1)
  
  # 4. histogram of studentized estimation errors together with standard normal density function
  hist(res$an, freq = FALSE, main = "Histogram of standardized estimation errors", 
       xlab = "standardized estimation errors")
  curve(dnorm(x), add = TRUE)
}



mu.pl <- c(0,0,0)
Sig.pl <- diag(1, nrow = 3)
mu.mn <- c(2, 1, -1)
Sig.mn <- rbind(c(1, 0.5, 0), 
                c(0.5, 1, 0.5),
                c(0, 0.5, 1))
P.pl <- function(n) {
  rmvnorm(n, mean = mu.pl, sigma = Sig.pl)
}
P.mn <- function(n) {
  rmvnorm(n, mean = mu.mn, sigma = Sig.mn)
}

rplc <- 200  # number of replications
sig <- 0.8   # parameter of the kernel functions
n.pl <- 500  # size of the 'plus' sample
n.mn <- 400  # size of the 'minus' sample
n.tg <- 300  # size of the target sample
pi.tg <- 0.4 # target probability
denominator <- 1/n.tg + 1/n.pl + 1/n.mn # normalization factor in central limit theorem
lam.tg <- (1/n.tg) / denominator
lam.pl <- (1/n.pl) / denominator
lam.mn <- (1/n.mn) / denominator
# asymptotic standard error of the projection (inner-product) estimator in the Gaussian case
# function asvar.pi.ipr() defined in <asvar-gauss.r>
sd.th <- sqrt(asvar.pi.ipr(lam.tg, lam.pl, lam.mn, pi.tg, mu.pl, Sig.pl, mu.mn, Sig.mn, sig) *
                denominator)
